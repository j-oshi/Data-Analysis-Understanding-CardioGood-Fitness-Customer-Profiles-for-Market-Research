{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/mortgage-300h-360m-5r.csv')\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "print(df.loc[df['Period'] == df['Period'].max() - 1, 'Principal Balance'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "\n",
    "# LLM from Ollama\n",
    "local_model = \"llama3.1:latest\"\n",
    "llm = ChatOllama(model=local_model, temperature=0)\n",
    "tool = PythonAstREPLTool(locals={\"df\": df})\n",
    "tool.invoke(\"df['Period'].mean()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([tool], tool_choice=tool.name)\n",
    "response = llm_with_tools.invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Monthly Payment' and 'Principal Balance' columns\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputKeyToolsParser\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "(llm_with_tools | parser).invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Monthly Payment' and 'Principal Balance' columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = f\"\"\"You have access to a pandas dataframe `df`. \n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "\n",
    "{df.head().to_markdown()}\n",
    "\n",
    "Given a user question, write the Python code to answer it. \n",
    "Return ONLY the valid Python code and nothing else. \n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "code_chain = prompt | llm_with_tools | parser\n",
    "response = code_chain.invoke({\"question\": \"What's is the value of Principal Balance at the last period?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = code_chain.invoke({\"question\": \"What's is the value of Principal Balance at the second to last period?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm_with_tools | parser | tool\n",
    "print(chain.invoke({\"question\": \"What's the correlation between Monthly Payment and Principal Balance\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Monthly Payment'].corr(df['Principal Balance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system = f\"\"\"You have access to a pandas dataframe `df`.\n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "\n",
    "{df.head().to_markdown()}\n",
    "\n",
    "Given a user question, write the Python code to answer it. \n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\n",
    "Respond directly to the question once you have enough information to answer it.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system,\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "        # This MessagesPlaceholder allows us to optionally append an arbitrary number of messages\n",
    "        # at the end of the prompt using the 'chat_history' arg.\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _get_chat_history(x: dict) -> list:\n",
    "    \"\"\"Parse the chain output up to this point into a list of chat history messages to insert in the prompt.\"\"\"\n",
    "    ai_msg = x[\"ai_msg\"]\n",
    "    tool_call_id = x[\"ai_msg\"].tool_calls[0][\"id\"]\n",
    "    tool_msg = ToolMessage(tool_call_id=tool_call_id, content=str(x[\"tool_output\"]))\n",
    "    return [ai_msg, tool_msg]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(ai_msg=prompt | llm_with_tools)\n",
    "    .assign(tool_output=itemgetter(\"ai_msg\") | parser | tool)\n",
    "    .assign(chat_history=_get_chat_history)\n",
    "    .assign(response=prompt | llm | StrOutputParser())\n",
    "    .pick([\"tool_output\", \"response\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"question\": \"What's the correlation between Monthly Payment and Principal Balance\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "\n",
    "# LLM from Ollama\n",
    "local_model = \"llama3.1:latest\"\n",
    "llm = ChatOllama(model=local_model, temperature=0)\n",
    "\n",
    "df = pd.read_csv('./data/mortgage-300h-360m-5r.csv')\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "pd_agent = create_pandas_dataframe_agent(llm, df, agent_type=\"tool-calling\", verbose=True, allow_dangerous_code=True)\n",
    "# pd_agent.run(\"what is the mean of the profit?\")\n",
    "query = \"What's the correlation between Monthly Payment and Principal Balance?\"\n",
    "query = query + \" using tool python_repl_ast\"\n",
    "pd_agent.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's the Principal Balance at the 360 period?\"\n",
    "query = query + \" using tool python_repl_ast\"\n",
    "pd_agent.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's is the total amount of interest paid after 360 months?\"\n",
    "query = query + \" using tool python_repl_ast\"\n",
    "pd_agent.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
